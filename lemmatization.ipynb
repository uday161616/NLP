{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lemmatization\n",
    "\n",
    "**Lemmatization** is a text-normalization technique that reduces words to their **lemma**—the dictionary/base form—using linguistic rules and a vocabulary.\n",
    "\n",
    "## Why it’s used\n",
    "- **Group word variants**: treat *connect*, *connecting*, *connected* as the same underlying term.\n",
    "- **Improve consistency** for tasks like search, topic modeling, and feature engineering.\n",
    "\n",
    "## Lemmatization vs. Stemming\n",
    "- **Stemming**: chops off endings (often produces non-words).  \n",
    "  Example: *studies → studi*\n",
    "- **Lemmatization**: returns a valid base word using language knowledge.  \n",
    "  Example: *studies → study*\n",
    "\n",
    "## Part-of-speech (POS) matters\n",
    "The same word can have different lemmas depending on its POS:\n",
    "- As a **noun**: *connections → connection*\n",
    "- As a **verb**: *connecting → connect*\n",
    "\n",
    "> In NLTK, `WordNetLemmatizer` often needs the correct POS (`\"n\"`, `\"v\"`, `\"a\"`, `\"r\"`) to produce the expected lemma.\n"
   ],
   "id": "3bdec7ce0a39e1a6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-31T07:46:48.625132Z",
     "start_time": "2026-01-31T07:46:48.622596Z"
    }
   },
   "source": "import nltk",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T07:46:48.921298Z",
     "start_time": "2026-01-31T07:46:48.918313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = [\n",
    "    \"connect\", \"connected\", \"connecting\", \"connection\", \"connections\",\n",
    "    \"compute\", \"computer\", \"computers\", \"computing\", \"computation\",\n",
    "    \"analyze\", \"analyzing\", \"analyzed\", \"analysis\", \"analyst\", \"analytics\"\n",
    "]"
   ],
   "id": "c46df455233bb0d3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T07:46:49.214727Z",
     "start_time": "2026-01-31T07:46:49.212168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "id": "a24ff6a5f09e2b38",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T07:50:41.983573Z",
     "start_time": "2026-01-31T07:50:41.980583Z"
    }
   },
   "cell_type": "code",
   "source": "lemmatizer.lemmatize(\"connecting\", pos=\"v\")",
   "id": "2a53ee2976de1276",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'connect'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T07:52:05.800414Z",
     "start_time": "2026-01-31T07:52:05.797506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+lemmatizer.lemmatize(word, pos=\"n\"))"
   ],
   "id": "967855e0d602c19d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect--->connect\n",
      "connected--->connected\n",
      "connecting--->connecting\n",
      "connection--->connection\n",
      "connections--->connection\n",
      "compute--->compute\n",
      "computer--->computer\n",
      "computers--->computer\n",
      "computing--->computing\n",
      "computation--->computation\n",
      "analyze--->analyze\n",
      "analyzing--->analyzing\n",
      "analyzed--->analyzed\n",
      "analysis--->analysis\n",
      "analyst--->analyst\n",
      "analytics--->analytics\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T07:51:28.246589Z",
     "start_time": "2026-01-31T07:51:28.244170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+lemmatizer.lemmatize(word, pos=\"v\"))"
   ],
   "id": "488680ac8276d05d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect--->connect\n",
      "connected--->connect\n",
      "connecting--->connect\n",
      "connection--->connection\n",
      "connections--->connections\n",
      "compute--->compute\n",
      "computer--->computer\n",
      "computers--->computers\n",
      "computing--->compute\n",
      "computation--->computation\n",
      "analyze--->analyze\n",
      "analyzing--->analyze\n",
      "analyzed--->analyze\n",
      "analysis--->analysis\n",
      "analyst--->analyst\n",
      "analytics--->analytics\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "792e411be73ed56e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
